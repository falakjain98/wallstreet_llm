{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from items import Item\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "# Log in to HuggingFace\n",
    "\n",
    "hf_token = os.environ['HF_TOKEN']\n",
    "login(hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 9543\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2388\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load in our dataset\n",
    "\n",
    "dataset = load_dataset(\"zeroshot/twitter-financial-news-sentiment\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$BYND - JPMorgan reels in expectations on Beyo...</td>\n",
       "      <td>0</td>\n",
       "      <td>bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$CCL $RCL - Nomura points to bookings weakness...</td>\n",
       "      <td>0</td>\n",
       "      <td>bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$CX - Cemex cut at Credit Suisse, J.P. Morgan ...</td>\n",
       "      <td>0</td>\n",
       "      <td>bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$ESS: BTIG Research cuts to Neutral https://t....</td>\n",
       "      <td>0</td>\n",
       "      <td>bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$FNKO - Funko slides after Piper Jaffray PT cu...</td>\n",
       "      <td>0</td>\n",
       "      <td>bearish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_category\n",
       "0  $BYND - JPMorgan reels in expectations on Beyo...      0        bearish\n",
       "1  $CCL $RCL - Nomura points to bookings weakness...      0        bearish\n",
       "2  $CX - Cemex cut at Credit Suisse, J.P. Morgan ...      0        bearish\n",
       "3  $ESS: BTIG Research cuts to Neutral https://t....      0        bearish\n",
       "4  $FNKO - Funko slides after Piper Jaffray PT cu...      0        bearish"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build training dataframe\n",
    "df_train = pd.DataFrame(dataset['train'])\n",
    "df_train['label_category'] = df_train.label.apply(lambda x: 'bearish' if x == 0 else 'bullish' if x == 1 else 'neutral' if x == 2 else 'unknown')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$ALLY - Ally Financial pulls outlook https://t...</td>\n",
       "      <td>0</td>\n",
       "      <td>bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$DELL $HPE - Dell, HPE targets trimmed on comp...</td>\n",
       "      <td>0</td>\n",
       "      <td>bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$PRTY - Moody's turns negative on Party City h...</td>\n",
       "      <td>0</td>\n",
       "      <td>bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$SAN: Deutsche Bank cuts to Hold</td>\n",
       "      <td>0</td>\n",
       "      <td>bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$SITC: Compass Point cuts to Sell</td>\n",
       "      <td>0</td>\n",
       "      <td>bearish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_category\n",
       "0  $ALLY - Ally Financial pulls outlook https://t...      0        bearish\n",
       "1  $DELL $HPE - Dell, HPE targets trimmed on comp...      0        bearish\n",
       "2  $PRTY - Moody's turns negative on Party City h...      0        bearish\n",
       "3                   $SAN: Deutsche Bank cuts to Hold      0        bearish\n",
       "4                  $SITC: Compass Point cuts to Sell      0        bearish"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build test dataframe\n",
    "df_test = pd.DataFrame(dataset['validation'])\n",
    "df_test['label_category'] = df_test.label.apply(lambda x: 'bearish' if x == 0 else 'bullish' if x == 1 else 'neutral' if x == 2 else 'unknown')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training points: 9543\n",
      "Testing points: 2388\n"
     ]
    }
   ],
   "source": [
    "# build training dataset\n",
    "train = []\n",
    "for i in range(len(df_train)):\n",
    "  datapoint = df_train.iloc[i]\n",
    "  train.append(Item(datapoint, datapoint['label_category']))\n",
    "print(f'Training points: {len(train)}')\n",
    "\n",
    "# build test dataset\n",
    "test = []\n",
    "for i in range(len(df_test)):\n",
    "  datapoint = df_test.iloc[i]\n",
    "  test.append(Item(datapoint, datapoint['label_category']))\n",
    "print(f'Testing points: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build test and train prompts\n",
    "train_prompts = [item.prompt for item in train if item.prompt]\n",
    "train_labels = [item.label for item in train if item.prompt]\n",
    "train_label_categories = [item.label_category for item in train if item.prompt]\n",
    "test_prompts = [item.test_prompt() for item in test if item.prompt]\n",
    "test_labels = [item.label for item in test if item.prompt]\n",
    "test_label_categories = [item.label_category for item in test if item.prompt]\n",
    "\n",
    "# Create a Dataset from the lists\n",
    "\n",
    "train_dataset = Dataset.from_dict({\"text\": train_prompts, \"label\": train_labels, \"label_category\": train_label_categories})\n",
    "test_dataset = Dataset.from_dict({\"text\": test_prompts, \"label\": test_labels, \"label_category\": test_label_categories})\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77fb7ebf09d2414680f1de6a750f16fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae2088a1c0a43f8a605fb39de4a5d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44936fa18fc45a0ba191e1005300110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b89174b560f4728b6120e72f33740aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9e8a70d0c24e85968c740d800ff680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                        : 100%|##########|  503kB /  503kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d61088d6f12491cbb4a76c58aa1ac8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6cd36b790ed4a7299168cbb119f3395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9291bad9b9ce4600a9b7f18cc2e2d008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7ec5ab159848a3b60b01277a06f6a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c16f0b4f2e54224a1db1737a79ab48b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                        : 100%|##########|  137kB /  137kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7e2947a21a411fb9c18eb8397e7f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/447 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/falakjain/financial_sentiment_data/commit/8fe6095b0c76cc685dce063294cc4f628612272c', commit_message='Upload dataset', commit_description='', oid='8fe6095b0c76cc685dce063294cc4f628612272c', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/falakjain/financial_sentiment_data', endpoint='https://huggingface.co', repo_type='dataset', repo_id='falakjain/financial_sentiment_data'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload data to HF\n",
    "\n",
    "HF_USER = \"falakjain\"\n",
    "DATASET_NAME = f\"{HF_USER}/financial_sentiment_data\"\n",
    "dataset.push_to_hub(DATASET_NAME, private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the training and test dataset so we don't have to execute all this code next time!\n",
    "\n",
    "with open('train.pkl', 'wb') as file:\n",
    "    pickle.dump(train, file)\n",
    "\n",
    "with open('test.pkl', 'wb') as file:\n",
    "    pickle.dump(test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'What is the financial sentiment of this tweet?\\n\\n$DELL $HPE - Dell, HPE targets trimmed on compute headwinds https\\n\\nSentiment is ',\n",
       " 'label': 0,\n",
       " 'label_category': 'bearish'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
